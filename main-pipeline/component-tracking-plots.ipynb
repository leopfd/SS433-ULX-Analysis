{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd04a3e-0dfd-4812-85fc-19b6741a3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from collections import defaultdict\n",
    "\n",
    "# Plotting Style Configuration\n",
    "plt.rcParams['figure.dpi'] = 400\n",
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Analysis Configuration\n",
    "base_dir = '/Users/leodrake/Documents/MIT/ss433/HRC_2024/2Dfits'\n",
    "center_pixel = 80.5\n",
    "pixscale_arcsec = 0.13175/4 # arcsec per pixel\n",
    "g1_component = 'g1'\n",
    "\n",
    "file_path = os.path.join(base_dir, 'component tracking results', 'tracker-4comp-1sigma-jittercorr-empPSF-000000-160160.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb4dc1-53d5-4b87-9f62-1a409ffe7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations_optimized(filename):\n",
    "    \"\"\"\n",
    "    Parses repeated ‘Observation:’ blocks from a file, optimized for\n",
    "    readability and efficiency.\n",
    "    \"\"\"\n",
    "    # Regex patterns are compiled once for performance.\n",
    "    # Using re.VERBOSE (via triple quotes) makes complex regex easier to read.\n",
    "    blk_re = re.compile(r\"^(Observation:\\s*(?P<obs_id>\\d+))(?P<body>.*?)(?=^Observation:|\\Z)\", re.S | re.M)\n",
    "    date_re = re.compile(r\"^\\s*Date:\\s*([\\d\\.]+)\\s*,\\s*Exptime:\\s*([\\d\\.]+)\", re.M)\n",
    "    rate_re = re.compile(r\"^\\s*(?P<comp>g\\d+)\\s*:\\s*(?P<nom>[\\d.eE+-]+)\\s*\\((?P<e1>[+-]?[\\d.eE+-]+)\\s*/\\s*(?P<e2>[+-]?[\\d.eE+-]+)\\)\", re.M)\n",
    "    # Modified regex: Allows for '-------' in the error columns\n",
    "    param_re = re.compile(r\"^\\s*(?P<comp>g\\d+)\\.(?P<param>xpos|ypos|ampl|fwhm)\\s+([\\d.eE+-]+)\\s+([+-]?[\\d.eE+-]+|-------)\\s+([+-]?[\\d.eE+-]+|-------)\", re.M)\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            text = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filename}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for m_blk in blk_re.finditer(text):\n",
    "        obs_id = int(m_blk.group('obs_id'))\n",
    "        body = m_blk.group('body')\n",
    "        \n",
    "        mjd, exptime = (float(m.group(1)), float(m.group(2))) if (m := date_re.search(body)) else (np.nan, np.nan)\n",
    "\n",
    "        pdat = defaultdict(dict)\n",
    "        for pm in param_re.finditer(body):\n",
    "            comp, param, best, lower_str, upper_str = pm.groups()\n",
    "            pdat[comp][param] = float(best)\n",
    "            \n",
    "            # store raw strings to convert later\n",
    "            pdat[comp][f'{param}_minus'] = lower_str\n",
    "            pdat[comp][f'{param}_plus'] = upper_str\n",
    "\n",
    "        for rm in rate_re.finditer(body):\n",
    "            comp, nom, e1_str, e2_str = rm.groups()\n",
    "            e1, e2 = float(e1_str), float(e2_str)\n",
    "            minus_err, plus_err = (abs(e1), abs(e2)) if e1 < 0 else (abs(e2), abs(e1))\n",
    "\n",
    "            row = {\n",
    "                'obs_id': obs_id, 'mjd': mjd, 'exptime': exptime, 'component': comp,\n",
    "                'nominal': float(nom), 'plus_err': plus_err, 'minus_err': minus_err,\n",
    "                **pdat.get(comp, {})\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # vectorize the conversion of error columns to numeric\n",
    "    err_cols = [c for c in df.columns if c.endswith('_minus') or c.endswith('_plus')]\n",
    "    for col in err_cols:\n",
    "        # pd.to_numeric with errors='coerce' turns '-------' into NaN automatically\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').abs()\n",
    "\n",
    "    if df['mjd'].isna().all():\n",
    "        df['mjd'] = df['obs_id'].astype('category').cat.codes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12614a-b7b4-4922-8491-94711cd74095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = parse_observations_optimized(file_path) # Assumes the optimized function from before\n",
    "\n",
    "# Vectorized Recenter on g1\n",
    "# isolate g1 positions\n",
    "g1_df = df[df['component'] == g1_component][['obs_id', 'xpos', 'ypos']]\n",
    "g1_df = g1_df.rename(columns={'xpos': 'g1_x', 'ypos': 'g1_y'})\n",
    "\n",
    "# merge g1 positions back into the main dataframe\n",
    "df = df.merge(g1_df, on='obs_id', how='left')\n",
    "\n",
    "# fill missing g1 positions with center pixel\n",
    "df['g1_x'] = df['g1_x'].fillna(center_pixel)\n",
    "df['g1_y'] = df['g1_y'].fillna(center_pixel)\n",
    "\n",
    "# calculate offsets vectorized\n",
    "df['dx'] = df['g1_x'] - center_pixel\n",
    "df['dy'] = df['g1_y'] - center_pixel\n",
    "\n",
    "# apply displacement\n",
    "df['xpos'] -= df['dx']\n",
    "df['ypos'] -= df['dy']\n",
    "\n",
    "# cleanup columns\n",
    "df.drop(columns=['dx', 'dy', 'g1_x', 'g1_y'], inplace=True)\n",
    "\n",
    "# Calculate Offsets, PA, Radius, and Propagate Errors\n",
    "df['xoff'] = df['xpos'] - center_pixel\n",
    "df['yoff'] = df['ypos'] - center_pixel\n",
    "\n",
    "pa_rad = np.arctan2(-df['xoff'], df['yoff'])\n",
    "df['PA'] = np.degrees(pa_rad)\n",
    "df['pa_rad'] = pa_rad # save radians for plotting later\n",
    "\n",
    "d2 = df['xoff']**2 + df['yoff']**2\n",
    "dpa_dx = np.divide(-df['yoff'], d2, out=np.full_like(d2, np.nan), where=d2 != 0)\n",
    "dpa_dy = np.divide(df['xoff'], d2, out=np.full_like(d2, np.nan), where=d2 != 0)\n",
    "\n",
    "df['PA_err_plus'] = np.degrees(np.sqrt((dpa_dx * df['xpos_plus'])**2 + (dpa_dy * df['ypos_plus'])**2))\n",
    "df['PA_err_minus'] = np.degrees(np.sqrt((dpa_dx * df['xpos_minus'])**2 + (dpa_dy * df['ypos_minus'])**2))\n",
    "\n",
    "df['radius'] = np.hypot(df['xoff'], df['yoff']) * pixscale_arcsec\n",
    "\n",
    "r_pix = df['radius'] / pixscale_arcsec\n",
    "is_zero = np.isclose(r_pix, 0)\n",
    "df['radius_plus_err'] = np.where(is_zero, np.hypot(df['xpos_plus'], df['ypos_plus']), np.sqrt((df['xoff']*df['xpos_plus'])**2 + (df['yoff']*df['ypos_plus'])**2)/r_pix) * pixscale_arcsec\n",
    "df['radius_minus_err'] = np.where(is_zero, np.hypot(df['xpos_minus'], df['ypos_minus']), np.sqrt((df['xoff']*df['xpos_minus'])**2 + (df['yoff']*df['ypos_minus'])**2)/r_pix) * pixscale_arcsec\n",
    "\n",
    "# Add a flag column for suspect data\n",
    "# First, ensure data is sorted by time to correctly identify the first three observations\n",
    "df.sort_values('mjd', inplace=True)\n",
    "\n",
    "# Get the unique obs_ids of the first three observations\n",
    "first_three_obs_ids = df['obs_id'].unique()[:3]\n",
    "\n",
    "# Initialize the flag column with a default 'clean' value\n",
    "df['flag'] = 'clean'\n",
    "\n",
    "# Create a mask to identify g2 components within the first three observations\n",
    "flag_mask = (df['component'] == 'g2') & (df['obs_id'].isin(first_three_obs_ids))\n",
    "\n",
    "# Apply the flag to the identified rows\n",
    "df.loc[flag_mask, 'flag'] = 'flagged_g2_suspect'\n",
    "print(f\"Flagged {len(first_three_obs_ids)} observations for component 'g2'.\")\n",
    "\n",
    "# Pivot Data and Save\n",
    "# Get the number of components *before* pivoting to create the filename\n",
    "n_comps = df['component'].nunique()\n",
    "output_csv_filename = os.path.join(base_dir, f'gaussian-component-data-{n_comps}-comps-1sigma-jittercorr-0000-4040.csv')\n",
    "\n",
    "# Now, perform the pivot operation\n",
    "pivoted = df.pivot_table(index='mjd', columns='component', values=['nominal', 'plus_err', 'minus_err'])\n",
    "df_nom, df_plus, df_minus = [pivoted[val].sort_index() for val in ['nominal', 'plus_err', 'minus_err']]\n",
    "\n",
    "# Save the main DataFrame to the new dynamic filename\n",
    "df.to_csv(output_csv_filename, index=False)\n",
    "print(f\"DataFrame with {n_comps} components saved to {output_csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecc88b-85f4-40ed-9d4e-2fa1e1e25b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_comp = df.groupby('component')\n",
    "\n",
    "# Create a dictionary to map components to colors\n",
    "comps = [c for c in df_nom.columns if c != 'g1']\n",
    "colors = ['dodgerblue', 'mediumseagreen',  'mediumslateblue','lightcoral']\n",
    "comp_colors = {comp: colors[i % len(colors)] for i, comp in enumerate(comps)}\n",
    "\n",
    "n = len(comps)\n",
    "delta = 0.02\n",
    "offsets = {c: (i - (n - 1) / 2) * delta for i, c in enumerate(comps)}\n",
    "\n",
    "pdf_filename = os.path.join(base_dir, f'position-rates-plots-{n+1}comp-1sigma-jittercorr-0000-4040.pdf')\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    # First figure: PA vs time + stacked count rates\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    gs  = GridSpec(n, 2, figure=fig, width_ratios=[1,1], hspace=0, wspace=0.3)\n",
    "\n",
    "    # Left: PA vs time\n",
    "    ax_pa = fig.add_subplot(gs[:,0])\n",
    "    for comp, color in comp_colors.items():\n",
    "        if comp in grouped_by_comp.groups:\n",
    "            grp = grouped_by_comp.get_group(comp)\n",
    "            if comp == 'g2':\n",
    "                # Split g2 data into clean and flagged sets\n",
    "                clean_grp = grp[grp['flag'] == 'clean']\n",
    "                flagged_grp = grp[grp['flag'] != 'clean']\n",
    "                \n",
    "                # Plot clean g2 points\n",
    "                if not clean_grp.empty:\n",
    "                    ax_pa.errorbar(\n",
    "                        clean_grp['mjd'], clean_grp['PA'],\n",
    "                        yerr=[clean_grp['PA_err_minus'], clean_grp['PA_err_plus']],\n",
    "                        marker='.', linestyle='-', capsize=3, color=color, label=comp\n",
    "                    )\n",
    "                # Plot flagged g2 points in yellow\n",
    "                if not flagged_grp.empty:\n",
    "                    ax_pa.errorbar(\n",
    "                        flagged_grp['mjd'], flagged_grp['PA'],\n",
    "                        yerr=[flagged_grp['PA_err_minus'], flagged_grp['PA_err_plus']],\n",
    "                        marker='.', linestyle='-', capsize=3, color='dodgerblue', \n",
    "                        markerfacecolor='yellow', markeredgecolor='k', label=None\n",
    "                    )\n",
    "            else:\n",
    "                # Plot all other components as normal\n",
    "                ax_pa.errorbar(\n",
    "                    grp['mjd'], grp['PA'],\n",
    "                    yerr=[grp['PA_err_minus'], grp['PA_err_plus']],\n",
    "                    marker='.', linestyle='-', capsize=3, color=color, label=comp\n",
    "                )\n",
    "    ax_pa.set_ylabel('Position Angle (°)')\n",
    "    ax_pa.set_xlabel('MJD')\n",
    "    ax_pa.set_title('Position Angle vs Time')\n",
    "    ax_pa.set_ylim(-180,180)\n",
    "    ax_pa.grid(True)\n",
    "    ax_pa.legend()\n",
    "\n",
    "    # Right: stacked count-rate panels\n",
    "    ax_bottom = None\n",
    "    flagged_mjds = df.loc[df['flag'] != 'clean', 'mjd'].unique()\n",
    "    for i_comp, focus in reversed(list(enumerate(comps))):\n",
    "        if i_comp == n - 1:\n",
    "            ax = fig.add_subplot(gs[i_comp, 1])\n",
    "            ax.set_xlabel('MJD')\n",
    "            ax_bottom = ax\n",
    "        else:\n",
    "            ax = fig.add_subplot(gs[i_comp, 1], sharex=ax_bottom)\n",
    "            ax.tick_params(labelbottom=False)\n",
    "        ax.grid(True, zorder=0)\n",
    "        for comp_name, current_color in comp_colors.items():\n",
    "            x_val = df_nom.index + offsets[comp_name]\n",
    "            y_val = df_nom[comp_name]\n",
    "            y_err_val = [df_minus[comp_name], df_plus[comp_name]]\n",
    "            alpha_val, line_style, label_text, z_order = (1.0, '-', comp_name, 10) if comp_name == focus else (0.3, '', None, 1)\n",
    "            ax.errorbar(\n",
    "                x_val, y_val, yerr=y_err_val, color=current_color,\n",
    "                marker='.', linestyle=line_style, capsize=3,\n",
    "                alpha=alpha_val, label=label_text, zorder=z_order\n",
    "            )\n",
    "            # Overlay flagged g2 points if this is the g2 component\n",
    "            if comp_name == 'g2' and len(flagged_mjds) > 0:\n",
    "                # Select the flagged data from the pivoted DataFrames\n",
    "                x_flagged = df_nom.loc[flagged_mjds].index + offsets[comp_name]\n",
    "                y_flagged = df_nom.loc[flagged_mjds, comp_name]\n",
    "                y_err_flagged = [df_minus.loc[flagged_mjds, comp_name], df_plus.loc[flagged_mjds, comp_name]]\n",
    "                ax.errorbar(\n",
    "                    x_flagged, y_flagged, yerr=y_err_flagged,\n",
    "                    marker='.', linestyle='', capsize=3, color='dodgerblue',\n",
    "                    markerfacecolor='yellow', markeredgecolor='k', zorder=z_order+1,\n",
    "                    alpha=alpha_val # <-- THIS IS THE FIX\n",
    "                )\n",
    "        ax.set_yticks([0.1,0.3])\n",
    "        if ax.has_data():\n",
    "             ax.legend(loc='upper left')\n",
    "\n",
    "    fig.text(0.73, 0.885, 'Component Count Rates', ha='center', va='bottom', fontsize=17)\n",
    "    fig.text(0.495, 0.5, 'Count rate (counts/s)', va='center', rotation='vertical')\n",
    "    \n",
    "    pdf.savefig(fig)\n",
    "    plt.show()\n",
    "\n",
    "    # Second figure: polar plot of PA on sky\n",
    "    fig_polar = plt.figure(figsize=(8,6))\n",
    "    ax_polar = fig_polar.add_subplot(111, projection='polar')\n",
    "    ax_polar.set_theta_zero_location('N')\n",
    "    ax_polar.set_theta_direction(1)\n",
    "    ax_polar.set_thetamin(-180)\n",
    "    ax_polar.set_thetamax(180)\n",
    "    ax_polar.set_rlabel_position(135)\n",
    "\n",
    "    for comp, color in comp_colors.items():\n",
    "        if comp in grouped_by_comp.groups:\n",
    "            grp = grouped_by_comp.get_group(comp)\n",
    "            if comp == 'g2':\n",
    "                clean_grp = grp[grp['flag'] == 'clean']\n",
    "                flagged_grp = grp[grp['flag'] != 'clean']\n",
    "                \n",
    "                # Plot clean g2 points\n",
    "                if not clean_grp.empty:\n",
    "                    ax_polar.errorbar(\n",
    "                        clean_grp['pa_rad'], clean_grp['radius'],\n",
    "                        xerr=[np.deg2rad(clean_grp['PA_err_minus'].fillna(0)), np.deg2rad(clean_grp['PA_err_plus'].fillna(0))],\n",
    "                        yerr=[clean_grp['radius_minus_err'].fillna(0), clean_grp['radius_plus_err'].fillna(0)],\n",
    "                        marker='.', linestyle='', color=color, capsize=3, label=comp\n",
    "                    )\n",
    "                # Plot flagged g2 points\n",
    "                if not flagged_grp.empty:\n",
    "                    ax_polar.errorbar(\n",
    "                        np.deg2rad(flagged_grp['PA']), flagged_grp['radius'],\n",
    "                        xerr=[np.deg2rad(flagged_grp['PA_err_minus'].fillna(0)), np.deg2rad(flagged_grp['PA_err_plus'].fillna(0))],\n",
    "                        yerr=[flagged_grp['radius_minus_err'].fillna(0), flagged_grp['radius_plus_err'].fillna(0)],\n",
    "                        marker='.', linestyle='', color='dodgerblue', capsize=3, label=None,\n",
    "                        markerfacecolor='yellow', markeredgecolor='k'\n",
    "                    )\n",
    "            else:\n",
    "                # Plot other components as normal\n",
    "                ax_polar.errorbar(\n",
    "                    np.deg2rad(grp['PA']), grp['radius'],\n",
    "                    xerr=[np.deg2rad(grp['PA_err_minus'].fillna(0)), np.deg2rad(grp['PA_err_plus'].fillna(0))],\n",
    "                    yerr=[grp['radius_minus_err'].fillna(0), grp['radius_plus_err'].fillna(0)],\n",
    "                    marker='.', linestyle='', color=color, capsize=3, label=comp\n",
    "                )\n",
    "\n",
    "    angles = np.arange(-150, 180, 30)\n",
    "    angles = np.append(angles, 180)\n",
    "    ax_polar.set_rmin(0)\n",
    "    ax_polar.set_thetagrids(angles, [f\"{int(a)}°\" for a in angles])\n",
    "    ax_polar.set_title('On Sky Component Positions (arcsec)')\n",
    "    ax_polar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "    pdf.savefig(fig_polar)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962407a-7819-4683-b5cf-a5122c21c18e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CIAO-4.17)",
   "language": "python",
   "name": "ciao-4.17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
